{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee85d29a-688a-408f-b3d9-ece30de00519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "sys.path.insert(0, '/home/andrea/Scrivania/Tesi/leonardo')\n",
    "from data import dataset\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6624923-12ae-471b-a993-f53f6f78c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/andrea/Scrivania/Tesi/leonardo/config_env.yaml\", 'r') as f:\n",
    "    config_env = yaml.safe_load(f)\n",
    "\n",
    "id_model = \"GCN_LSTM\"\n",
    "with open(os.path.join(config_env['paths']['config'], f\"{id_model}.yaml\"), 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    \n",
    "config.update(config_env)\n",
    "\n",
    "if 'epochs' in config_env['setting'].keys():\n",
    "    config['training']['epochs'] = config_env['setting']['epochs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3c3193-dc2d-4497-bc8a-f5aff2450b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(config['paths']['data'], 'covid.csv'), index_col=0)\n",
    "data.data = pd.to_datetime(data.data, format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "data.rename(columns = {'nuovi_casi':'y'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05374ae1-1cf5-4adc-8915-a08df1bfd015",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 df: pd.DataFrame,\n",
    "                 past_step:int, \n",
    "                 future_step:int, \n",
    "                 past_variables: list, \n",
    "                 future_variables: list, \n",
    "                 y:list,\n",
    "                 adj: np.array,\n",
    "                 nodes: int, \n",
    "                 timedelta:str = 'D',\n",
    "                 col_data: str = \"data\"):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            df (pandas.Dataframe): Path to the csv file with annotations.\n",
    "            adj : adjacency matrix\n",
    "            nodes : number of nodes\n",
    "            past_step (int): previous step to look back\n",
    "            future_step (int): future step to look for\n",
    "            col_data (str): it indicate the columns that gives the indication about the time\n",
    "        \"\"\"\n",
    "\n",
    "        self.x = []\n",
    "        self.x_fut = []\n",
    "        self.y = []\n",
    "        self.adj = adj\n",
    "        date = df[col_data].unique()\n",
    "        date.sort()\n",
    "        start = 0\n",
    "        dt = np.diff(date[:past_step+future_step]) == np.timedelta64(1, timedelta)\n",
    "        while any(not x for x in dt):\n",
    "            start +=1\n",
    "            dt = np.diff(date[start:past_step+future_step+ start]) == np.timedelta64(1, timedelta)\n",
    "        \n",
    "        for i in tqdm(range(start, len(date)-future_step-past_step-1)):\n",
    "            if date[i+past_step+future_step]-date[i+past_step+future_step-1] == np.timedelta64(1, timedelta): \n",
    "                tmp_x = df[df[col_data].isin(date[i:i+past_step])].drop(columns = col_data).values\n",
    "                tmp_y = df[df[col_data].isin(date[i+past_step:i+past_step+future_step])]\n",
    "                \n",
    "                self.x_fut.append(tmp_y[future_variables].values.reshape(future_step, nodes, -1))\n",
    "                self.x.append(tmp_x.reshape(past_step, nodes, -1))\n",
    "                self.y.append(tmp_y[y].values.reshape(future_step, -1).transpose())\n",
    "            else:\n",
    "                i += past_step+future_step\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.x_fut[idx], self.y[idx], self.adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac8c2f44-b660-4e71-ae92-e6378ac7d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_step = config['setting']['past_step']\n",
    "future_step = config['setting']['future_step']\n",
    "PATH = os.path.join(config['paths']['data'], config['setting']['dataset'], f\"{past_step}_{future_step}.pkl\")\n",
    "\n",
    "if os.path.exists(PATH):\n",
    "    with open(PATH, \"rb\") as f:\n",
    "        ds = pickle.load(f)\n",
    "else:\n",
    "    #carico la matrice di adiacenza\n",
    "    with open(os.path.join(config['paths']['adj'],\"adj_totale.pkl\"), \"rb\") as f:\n",
    "        adj = pickle.load(f)\n",
    "    ds = dataset(df = data, \n",
    "                 past_step = past_step,\n",
    "                 future_step = future_step, \n",
    "                 nodes = len(data.codice_provincia.unique()),\n",
    "                 past_variables=data.columns.tolist(),\n",
    "                 future_variables = data.columns[-7:].tolist(), \n",
    "                 y = ['y'],\n",
    "                 adj = adj, \n",
    "                 timedelta = 'D')\n",
    "    with open(PATH, 'wb') as f:\n",
    "        pickle.dump(ds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54bbf9d0-99e5-4ebb-b1d2-68dd1ed971b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 30, 107, 21])\n",
      "torch.Size([14, 50, 107, 7])\n",
      "torch.Size([14, 107, 50])\n"
     ]
    }
   ],
   "source": [
    "len_train = int(len(ds)*0.75)\n",
    "len_val = len(ds)-len_train\n",
    "batch_size = 14\n",
    "df_train, df_val = torch.utils.data.random_split(dataset=ds, lengths = [len_train, len_val])\n",
    "dl_train = DataLoader(dataset=df_train, batch_size=batch_size, shuffle=True)\n",
    "dl_val = DataLoader(dataset=df_val, batch_size=batch_size, shuffle=True)\n",
    "x_past, x_fut, y, adj = next(iter(dl_train))\n",
    "config['setting']['in_feat_past'] = x_past.shape[-1]\n",
    "config['setting']['in_feat_future'] = x_fut.shape[-1]\n",
    "print(x_past.shape)\n",
    "print(x_fut.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2521f06e-35cc-4d37-9eb7-cec38e477211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(model, \n",
    "         config:yaml,\n",
    "         loss_training: list, \n",
    "         loss_validation: list, \n",
    "         name:str,\n",
    "         dl_train: DataLoader,\n",
    "         dl_val: DataLoader, \n",
    "         show = False):\n",
    "\n",
    "    fig = px.line({\"epochs\": range(1,len(loss_training)+1), \n",
    "                                   \"train\": loss_training, \n",
    "                                   \"validation\": loss_validation}, \n",
    "                                  x = \"epochs\", \n",
    "                                  y = [\"train\", \"validation\"], \n",
    "                                  title= f\"training loss for {name}\")\n",
    "    fig.add_vline(x = np.argsort(loss_validation)[0]+1)\n",
    "    fig.add_hline(y = np.min(loss_validation))\n",
    "    fig.write_html(os.path.join(config['paths']['fig'], config['setting']['dataset'], f\"loss_gnn_{name}.html\"))\n",
    "    if show:\n",
    "        fig.show()\n",
    "    model = model.cpu()\n",
    "    model.device = torch.device('cpu')\n",
    "    \n",
    "    x_past_train, x_fut_train, y_train, adj_train = next(iter(dl_train))\n",
    "    x_past_val, x_fut_val, y_val, adj_val = next(iter(dl_val))\n",
    "    yh_train = model(x_past_train.float().to(model.device), x_fut_train.float().to(model.device), adj_train[0].to(model.device)).detach().numpy()\n",
    "    yh_val = model(x_past_val.float().to(model.device), x_fut_val.float().to(model.device), adj_val[0].to(model.device)).detach().cpu().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(nrows = y_val.shape[1], \n",
    "                           ncols = 2, \n",
    "                           constrained_layout = True,\n",
    "                           figsize = (20, 3*y_val.shape[1]))\n",
    "    \n",
    "    for day in range(y_val.shape[1]):\n",
    "        ax[day, 0].plot(yh_train[0,day], label = \"estimate\")\n",
    "        ax[day, 0].plot(y_train[0,day], label =\"real\")\n",
    "    \n",
    "        ax[day, 1].plot(yh_val[0,day], label = \"estimate\")\n",
    "        ax[day, 1].plot(y_val[0,day], label =\"real\")\n",
    "        ax[day, 0].legend()\n",
    "        ax[day, 1].legend()\n",
    "    \n",
    "        ax[day, 0].title.set_text(f\"day {day +1} train\")\n",
    "        ax[day, 1].title.set_text(f\"day {day +1} validation\")\n",
    "    fig.suptitle(' Comparison between estimation and reality ', fontsize=20) \n",
    "    \n",
    "    path = os.path.join(config['paths']['fig'], config['setting']['dataset'], f\"{name}.png\")\n",
    "    plt.savefig(path)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close(fig)\n",
    "# id_model = \"GAT_LSTMseq2seq\"\n",
    "# plot(model = trainer.model,\n",
    "#      config = config,\n",
    "#      loss_training = trainer.loss_train, \n",
    "#      loss_validation = trainer.loss_val, \n",
    "#      dl_train = dl_train, \n",
    "#         dl_val = dl_val, \n",
    "#         name = f\"{id_model}\", \n",
    "#         show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe417684-0e5d-4615-811b-5e7cde9bc3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/home/andrea/Scrivania/Tesi/leonardo')\n",
    "from models.GAT_LSTMseq2seq.model import GAT_LSTMseq2seq\n",
    "from models.GAT_LSTM.model import GAT_LSTM\n",
    "from models.GLSTMseq2seq.model import GLSTMseq2seq\n",
    "from models.GCN_LSTM.model import GCN_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b9f125-3285-45b1-b15a-ba7f27303cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 50, 107])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")       \n",
    "model = GAT_LSTMseq2seq(in_feat_past = config['setting']['in_feat_past'],\n",
    "                        in_feat_fut = config['setting']['in_feat_future'],\n",
    "                        past = past_step,\n",
    "                        future = future_step,\n",
    "                        categorical_past = config['categorical'][config['setting']['dataset']]['past'],\n",
    "                        categorical_future = config['categorical'][config['setting']['dataset']]['future'],\n",
    "                        device = device).to(device)\n",
    "model.load_state_dict(torch.load(os.path.join(config['paths']['models'], f'GAT_LSTMseq2seq_{past_step}_{future_step}.pt')))\n",
    "model(x_past, x_fut, adj[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73b39f68-0fb2-4c27-84fe-ee00e9d93280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1296,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1215/1215 [02:41<00:00,  7.50it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [07:15<00:00, 33.53s/it]\n"
     ]
    }
   ],
   "source": [
    "def plot_stream(model, \n",
    "                df: pd.DataFrame, \n",
    "                config: yaml, \n",
    "                past_variables:list, \n",
    "                future_variables: list,\n",
    "                col_data :list,\n",
    "                adj:torch.tensor,\n",
    "                nodes:int, \n",
    "                name:str, \n",
    "                node: int = 3, \n",
    "                timedelta: str = 'D'):\n",
    "    node = min(node, nodes)-1\n",
    "    past_step = model.past\n",
    "    future_step = model.future\n",
    "    date = np.sort(data.data.unique())\n",
    "    y = []\n",
    "    yh = []\n",
    "    start = 0\n",
    "\n",
    "    x_past = df.groupby('data').apply(lambda x : np.array(x[past_variables].values))\n",
    "    x_fut = df.groupby('data').apply(lambda x : np.array(x[future_variables].values))\n",
    "    y_group = df.groupby('data').apply(lambda x : np.array(x['y'].values))\n",
    "    print(y_group.shape)\n",
    "    dt = np.diff(date[:past_step+future_step]) == np.timedelta64(1, timedelta)\n",
    "    while any(not x for x in dt):\n",
    "        start +=1\n",
    "        dt = np.diff(date[start:past_step+future_step+ start]) == np.timedelta64(1, timedelta)\n",
    "    \n",
    "    for i in tqdm(range(start, len(date)-future_step-past_step-1)):\n",
    "        if date[i+past_step+future_step]-date[i+past_step+future_step-1] == np.timedelta64(1, timedelta): \n",
    "            tmp_x_past = np.stack(x_past[x_past.index.isin(date[i:i+past_step])].values)\n",
    "            tmp_x_fut = np.stack(x_fut[x_fut.index.isin(date[i+past_step:i+past_step+future_step])].values)\n",
    "            # import pdb\n",
    "            # pdb.set_trace()\n",
    "            \n",
    "            yh_tmp =model(torch.from_numpy(tmp_x_past).unsqueeze(0).to(model.device), \n",
    "                          torch.from_numpy(tmp_x_fut).unsqueeze(0).to(model.device),\n",
    "                          adj.to(model.device)).detach().cpu()\n",
    "            yh.append(F.relu(yh_tmp))\n",
    "            \n",
    "            tmp_y = np.vstack(y_group[y_group.index.isin(date[i+past_step:i+past_step+future_step])].values)\n",
    "            y.append([tmp_y])\n",
    "        \n",
    "        else:\n",
    "             i += past_step+future_step \n",
    "\n",
    "    yh = torch.cat(yh)\n",
    "    y = np.vstack(y) \n",
    "    f = y.shape[-1]\n",
    "    for step in tqdm(range(37, model.future)):\n",
    "        fig, ax = plt.subplots(nrows = f, \n",
    "                                   ncols = 1, \n",
    "                                   constrained_layout = True,\n",
    "                                   figsize = (20,f*3))\n",
    "    \n",
    "        for n in range(f):\n",
    "            ax[n].plot(y[:,step, n], label = 'real')\n",
    "            ax[n].plot(yh[:,step, n], label = 'estimated')\n",
    "            ax[n].legend()  \n",
    "\n",
    "            err = np.mean(np.abs(yh[:,step, n].numpy()-y[:,step, n]))\n",
    "            ax[n].title.set_text(f\"node {n}, step {step} train, err = {err}\")\n",
    "        \n",
    "        path = os.path.join(config['paths']['fig'], config['setting']['dataset'], 'flows', name)\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        plt.savefig(os.path.join(path, f\"step{step+1}.png\"))\n",
    "        plt.close(fig)\n",
    "        \n",
    "plot_stream(model,\n",
    "            df = data, \n",
    "            config = config,\n",
    "            past_variables = data.drop(columns=\"data\").columns.tolist(),\n",
    "            future_variables = data.columns[-7:].tolist(),\n",
    "            adj = adj[0],\n",
    "            col_data = ['data'],\n",
    "            nodes=len(data.codice_provincia.unique()), \n",
    "            name = \"GAT_LSTMseq2seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab188421-cf69-47bf-9c72-be6c3fe377fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
