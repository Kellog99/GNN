{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880f767c-063e-41ab-b717-159c314557f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89286644-478c-45ea-b4c4-51357958de33",
   "metadata": {},
   "source": [
    "Carico il configuratore che tiene traccia di tutte le informazioni generali "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70ea09f7-d49a-4aff-bcd2-e1bf7e5c97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "with open(\"./config.yaml\", 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad78eea9-973f-4b72-87e9-590207299d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'codice_regione',\n",
       " 'ricoverati_con_sintomi',\n",
       " 'terapia_intensiva',\n",
       " 'totale_ospedalizzati',\n",
       " 'isolamento_domiciliare',\n",
       " 'dimessi_guariti',\n",
       " 'deceduti']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['dataset']['col_region']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5028948-9440-480c-8007-9bb486239ecc",
   "metadata": {},
   "source": [
    "# Download Dati\n",
    "\n",
    "In questa parte carico i `.csv` e gli organizzo in modo tale che siano ordinati per\n",
    "\n",
    "`(data, denominazione_regionale, denominazione_provincia)`\n",
    "\n",
    "Inoltre pulisco i vari datase poiché ci sono una serie di righe che presentano delle problematicità in termini di valori.\n",
    "\n",
    "La matrice di adiacenza generale è stata creata connettendo tutte le provincie di una determinata regione, in modo tale da mantenere una similitudine con il problema originario. Inoltre, per non distaccarsi troppo con la realtà, sono state inserite delle connessioni tra regioni dato che quest'ultime non sono isolate. In particolare sono state aggiunte connessioni tra tutti i capoluoghi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83b263e7-92d5-41c3-b938-4feab58d4188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj(config: yaml):\n",
    "    if os.path.exists(os.path.join(config['paths']['adj'],\"adj_totale.pkl\")):\n",
    "        with open(os.path.join(config['paths']['adj'],\"adj_totale.pkl\"), \"rb\") as f:\n",
    "            adj = pickle.load(f)\n",
    "    else:\n",
    "        codice_reg_prov = pd.read_csv(os.path.join(config['paths']['data'], \"codice_reg_prov.csv\"), index_col=0)\n",
    "\n",
    "        # Carico un dizionario in cui le chiavi sono le regioni e i valori sono i rispettivi capoluohi\n",
    "        with open(os.path.join(config['paths']['data'], \"capoluoghi.json\"), 'r') as f:\n",
    "            capoluoghi = json.load(f)\n",
    "        \n",
    "        adjs = {}\n",
    "        adj = np.zeros((len(codice_reg_prov), len(codice_reg_prov)))\n",
    "        i = 0\n",
    "        index_capoluoghi = []\n",
    "        d = codice_reg_prov.groupby('denominazione_provincia').codice_provincia.max().to_dict()\n",
    "        regioni = codice_reg_prov.groupby(by=['codice_regione']).codice_provincia.unique()\n",
    "        \n",
    "        for cod_reg in tqdm(regioni.index):\n",
    "            codici_provincia = regioni[cod_reg]\n",
    "            n_prov = len(codici_provincia)\n",
    "            adjs[cod_reg] = np.ones((n_prov, n_prov))-np.eye(n_prov)\n",
    "            adj[i:i+n_prov, i:i+n_prov] = adjs[cod_reg]\n",
    "\n",
    "            region = codice_reg_prov[codice_reg_prov.codice_regione==cod_reg].denominazione_regione.values[0]\n",
    "            codice_capoluogo = codice_reg_prov[codice_reg_prov.denominazione_provincia==capoluoghi[region]].codice_provincia.values[0]\n",
    "            pos = np.where(codici_provincia == codice_capoluogo)[0][0]\n",
    "            index_capoluoghi.append(i+pos)\n",
    "            \n",
    "            \n",
    "            with open(os.path.join(config['paths']['adj'],f\"adj_{region}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(adj, f)\n",
    "                \n",
    "            i += n_prov\n",
    "        for ind_r in index_capoluoghi:\n",
    "            for ind_c in index_capoluoghi:\n",
    "                if ind_r != ind_c:\n",
    "                    adj[ind_r, ind_c] = 1\n",
    "                \n",
    "        with open(os.path.join(config['paths']['adj'],\"adj_totale.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(adj, f)\n",
    "        \n",
    "    return adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e1ab253-e1e1-447e-9627-ad5560fb24a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1298/1298 [00:01<00:00, 834.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>totale_casi</th>\n",
       "      <th>ricoverati_con_sintomi</th>\n",
       "      <th>terapia_intensiva</th>\n",
       "      <th>totale_ospedalizzati</th>\n",
       "      <th>isolamento_domiciliare</th>\n",
       "      <th>dimessi_guariti</th>\n",
       "      <th>deceduti</th>\n",
       "      <th>nuovi_casi</th>\n",
       "      <th>variazione_ricoverati_con_sintomi</th>\n",
       "      <th>...</th>\n",
       "      <th>variazione_dimessi_guariti</th>\n",
       "      <th>variazione_deceduti</th>\n",
       "      <th>variazione_isolamento_domiciliare</th>\n",
       "      <th>codice_regione</th>\n",
       "      <th>codice_provincia</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>15875</td>\n",
       "      <td>307</td>\n",
       "      <td>14</td>\n",
       "      <td>321</td>\n",
       "      <td>1264</td>\n",
       "      <td>25649</td>\n",
       "      <td>4077</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>1321</td>\n",
       "      <td>307</td>\n",
       "      <td>14</td>\n",
       "      <td>321</td>\n",
       "      <td>1264</td>\n",
       "      <td>25649</td>\n",
       "      <td>4077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>2787</td>\n",
       "      <td>307</td>\n",
       "      <td>14</td>\n",
       "      <td>321</td>\n",
       "      <td>1264</td>\n",
       "      <td>25649</td>\n",
       "      <td>4077</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>2853</td>\n",
       "      <td>307</td>\n",
       "      <td>14</td>\n",
       "      <td>321</td>\n",
       "      <td>1264</td>\n",
       "      <td>25649</td>\n",
       "      <td>4077</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>1874</td>\n",
       "      <td>307</td>\n",
       "      <td>14</td>\n",
       "      <td>321</td>\n",
       "      <td>1264</td>\n",
       "      <td>25649</td>\n",
       "      <td>4077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>4063</td>\n",
       "      <td>307</td>\n",
       "      <td>14</td>\n",
       "      <td>321</td>\n",
       "      <td>1264</td>\n",
       "      <td>25649</td>\n",
       "      <td>4077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>1045</td>\n",
       "      <td>307</td>\n",
       "      <td>14</td>\n",
       "      <td>321</td>\n",
       "      <td>1264</td>\n",
       "      <td>25649</td>\n",
       "      <td>4077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>1136</td>\n",
       "      <td>307</td>\n",
       "      <td>14</td>\n",
       "      <td>321</td>\n",
       "      <td>1264</td>\n",
       "      <td>25649</td>\n",
       "      <td>4077</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>1194</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1044</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>3886</td>\n",
       "      <td>501</td>\n",
       "      <td>47</td>\n",
       "      <td>548</td>\n",
       "      <td>11092</td>\n",
       "      <td>65323</td>\n",
       "      <td>16624</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>492.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-230.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        data  totale_casi  ricoverati_con_sintomi  terapia_intensiva  \\\n",
       "0 2020-06-26        15875                     307                 14   \n",
       "1 2020-06-26         1321                     307                 14   \n",
       "2 2020-06-26         2787                     307                 14   \n",
       "3 2020-06-26         2853                     307                 14   \n",
       "4 2020-06-26         1874                     307                 14   \n",
       "5 2020-06-26         4063                     307                 14   \n",
       "6 2020-06-26         1045                     307                 14   \n",
       "7 2020-06-26         1136                     307                 14   \n",
       "8 2020-06-26         1194                       2                  0   \n",
       "9 2020-06-26         3886                     501                 47   \n",
       "\n",
       "   totale_ospedalizzati  isolamento_domiciliare  dimessi_guariti  deceduti  \\\n",
       "0                   321                    1264            25649      4077   \n",
       "1                   321                    1264            25649      4077   \n",
       "2                   321                    1264            25649      4077   \n",
       "3                   321                    1264            25649      4077   \n",
       "4                   321                    1264            25649      4077   \n",
       "5                   321                    1264            25649      4077   \n",
       "6                   321                    1264            25649      4077   \n",
       "7                   321                    1264            25649      4077   \n",
       "8                     2                       2             1044       146   \n",
       "9                   548                   11092            65323     16624   \n",
       "\n",
       "   nuovi_casi  variazione_ricoverati_con_sintomi  ...  \\\n",
       "0         5.0                               -9.0  ...   \n",
       "1         0.0                               -9.0  ...   \n",
       "2         2.0                               -9.0  ...   \n",
       "3         2.0                               -9.0  ...   \n",
       "4         0.0                               -9.0  ...   \n",
       "5         0.0                               -9.0  ...   \n",
       "6         1.0                               -9.0  ...   \n",
       "7         3.0                               -9.0  ...   \n",
       "8         0.0                                0.0  ...   \n",
       "9         8.0                             -121.0  ...   \n",
       "\n",
       "   variazione_dimessi_guariti  variazione_deceduti  \\\n",
       "0                       105.0                  6.0   \n",
       "1                       105.0                  6.0   \n",
       "2                       105.0                  6.0   \n",
       "3                       105.0                  6.0   \n",
       "4                       105.0                  6.0   \n",
       "5                       105.0                  6.0   \n",
       "6                       105.0                  6.0   \n",
       "7                       105.0                  6.0   \n",
       "8                         1.0                  0.0   \n",
       "9                       492.0                 16.0   \n",
       "\n",
       "   variazione_isolamento_domiciliare  codice_regione  codice_provincia  year  \\\n",
       "0                              -86.0               1                 1     0   \n",
       "1                              -86.0               1                 2     0   \n",
       "2                              -86.0               1                 3     0   \n",
       "3                              -86.0               1                 4     0   \n",
       "4                              -86.0               1                 5     0   \n",
       "5                              -86.0               1                 6     0   \n",
       "6                              -86.0               1                96     0   \n",
       "7                              -86.0               1               103     0   \n",
       "8                               -1.0               2                 7     0   \n",
       "9                             -230.0               3                12     0   \n",
       "\n",
       "   month  day  dayofweek  weekend  \n",
       "0      5   25          4        0  \n",
       "1      5   25          4        0  \n",
       "2      5   25          4        0  \n",
       "3      5   25          4        0  \n",
       "4      5   25          4        0  \n",
       "5      5   25          4        0  \n",
       "6      5   25          4        0  \n",
       "7      5   25          4        0  \n",
       "8      5   25          4        0  \n",
       "9      5   25          4        0  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fill_dataset(df: pd, \n",
    "                 config:yaml):\n",
    "    # questa procedura serve solo ad inserire i dati sulle province mancanti\n",
    "    # questa procedura serve solo ad inserire i dati sulle province mancanti\n",
    "    d = []\n",
    "    feat = df.shape[1]\n",
    "    codici = list(df.codice_provincia.unique())\n",
    "    codice_reg_prov = {tuple(x) for x in df[config['dataset']['col_categorical_prov']].values.tolist()}\n",
    "    codice_reg_prov = pd.DataFrame(codice_reg_prov, columns=config['dataset']['col_categorical_prov'])\n",
    "    codice_reg_prov = codice_reg_prov.sort_values(by = ['codice_regione', 'codice_provincia']).reset_index(drop = True)\n",
    "    \n",
    "    codici = list(codice_reg_prov.codice_provincia.unique())\n",
    "    for data in tqdm(df.data.unique(), desc = \"filling\"):\n",
    "        tmp = df[df.data == data]\n",
    "        if len(tmp) != len(codici):\n",
    "            # individue le province mancanti\n",
    "            codici_mancanti = [x for x in codici if x not in tmp.codice_provincia.unique()]\n",
    "            tmp = pd.concat([tmp, codice_reg_prov[codice_reg_prov.codice_provincia.isin(codici_mancanti)]])        \n",
    "            tmp.data = data\n",
    "            tmp = tmp.fillna(0)\n",
    "    \n",
    "            if len(tmp) != len(codici):\n",
    "                import pdb\n",
    "                pdb.set_trace()\n",
    "        d.append(tmp)\n",
    "    df = pd.concat(d).sort_values(by = ['data','codice_regione', 'codice_provincia']).reset_index(drop = True)\n",
    "    df = df[list(df.columns.drop(['codice_regione', 'codice_provincia']))+['codice_regione', 'codice_provincia']]\n",
    "    return df\n",
    "    \n",
    "def get_dataset(config: yaml):\n",
    "    files = [\"covid\", \"covid_province\", \"covid_regioni\"]\n",
    "    exists = [os.path.exists(os.path.join(config['paths']['data'], f\"{file}.csv\")) for file in files]\n",
    "\n",
    "\n",
    "    ############## Checking if all the files that I need exists #######################\n",
    "    if  np.all(exists):\n",
    "        tmp = pd.read_csv(os.path.join(config['paths']['data'], f\"covid.csv\"), index_col=0)\n",
    "        tmp.data = pd.to_datetime(tmp.data, format='%Y-%m-%d')\n",
    "        return tmp\n",
    "        \n",
    "    else:\n",
    "        ########## I create take the dataset for the provinces\n",
    "        if os.path.exists(os.path.join(config['paths']['data'],\"covid_province.csv\")):\n",
    "            provincials = pd.read_csv(os.path.join(config['paths']['data'],\"covid_province.csv\"), index_col = 0)\n",
    "            provincials['data'] = pd.to_datetime(provincials['data'], format='%Y-%m-%d')\n",
    "        else:\n",
    "            data = []\n",
    "            for csv in tqdm(os.listdir(os.path.join(config['paths']['raw_data'],\"dati-province\")), desc = \"provincia\"):\n",
    "                if csv.split(\".\")[-1] == \"csv\":\n",
    "                    tmp = pd.read_csv(os.path.join(config['paths']['raw_data'],\"dati-province\",csv), \n",
    "                                      usecols = ['data', 'codice_regione', 'codice_provincia', 'totale_casi'])\n",
    "                    data.append(tmp)\n",
    "            \n",
    "            data = pd.concat(data)\n",
    "            data.reset_index(drop = True, inplace=True)\n",
    "            data.data = data.data.apply(lambda x: x.split(\"T\")[0])\n",
    "            data.data = pd.to_datetime(data['data'], format='%Y-%m-%d')\n",
    "            \n",
    "            # Riduco il dataset con le variabili che servono\n",
    "            # Inoltre trasformo la conta totale dei positivi per ogni regione in nuovi positivi\n",
    "            provincials = data.drop_duplicates()\n",
    "            provincials = provincials[-(provincials.codice_provincia>200)]\n",
    "            \n",
    "            # codici relative alle province che sono state male elaborate\n",
    "            provincials = provincials[-provincials.codice_regione.isin([21,22])]\n",
    "            provincials.to_csv(os.path.join(config['paths']['data'],\"covid_province.csv\"))\n",
    "        \n",
    "        if os.path.exists(os.path.join(config['paths']['data'], \"covid_regioni.csv\")):\n",
    "            regions = pd.read_csv(os.path.join(config['paths']['data'],\"covid_regioni.csv\"), index_col=0)\n",
    "            regions['data'] = pd.to_datetime(regions['data'], format='%Y-%m-%d')\n",
    "        else:\n",
    "            ########## I create take the dataset for the regions\n",
    "            data = []\n",
    "            for csv in tqdm(os.listdir(os.path.join(config['paths']['raw_data'],\"dati-regioni\")), desc = \"regione\"):\n",
    "                if csv.split(\".\")[-1] == \"csv\":\n",
    "                    data.append(pd.read_csv(os.path.join(config['paths']['raw_data'],\"dati-regioni\",csv)))\n",
    "            data = pd.concat(data).drop_duplicates().reset_index(drop = True)\n",
    "            \n",
    "            # Trento\n",
    "            data.codice_regione = data.codice_regione.replace(21, 4)\n",
    "            # Bolzano\n",
    "            data.codice_regione = data.codice_regione.replace(22, 4)\n",
    "            # in questo modo sommo tutte le variabili delle due provincie\n",
    "            # non ci sono problemi perché le variabili rimanenti sono solo numeriche \n",
    "            data = data.groupby(by = ['data', 'codice_regione']).sum().reset_index()\n",
    "            \n",
    "            ############# Estraggo solo le colonne che sono utili ######\n",
    "            regions = data[config['dataset']['col_region']]\n",
    "            regions.data = regions.data.apply(lambda x: x.split(\"T\")[0])\n",
    "            regions.data = pd.to_datetime(regions['data'], format='%Y-%m-%d')\n",
    "            \n",
    "            regions = regions.drop_duplicates().reset_index(drop = True)\n",
    "            regions.to_csv(os.path.join(config['paths']['data'],\"covid_regioni.csv\"))\n",
    "                    \n",
    "        # Creo il dataset completo \n",
    "        if os.path.exists(os.path.join(config['paths']['data'],\"covid.csv\")):\n",
    "            df = pd.read_csv(os.path.join(config['paths']['data'], \"covid.csv\"), index_col=0)\n",
    "            df['data'] = pd.to_datetime(df['data'], format='%Y-%m-%d')\n",
    "\n",
    "        else:\n",
    "            df = pd.merge(provincials, regions, \n",
    "                          how = \"inner\",  \n",
    "                          on = ['data','codice_regione']) \n",
    "            df = df.sort_values(by = ['data','codice_regione', 'codice_provincia']).reset_index(drop = True)\n",
    "            \n",
    "            codice_reg_prov = {tuple(x) for x in df[config['dataset']['col_categorical']].values.tolist()}\n",
    "            codice_reg_prov = pd.DataFrame(codice_reg_prov, columns=config['dataset']['col_categorical'])\n",
    "\n",
    "            ################# Cleaning the dataset ###################\n",
    "            n_nodes = len(df.codice_provincia.unique())\n",
    "            dates = df.data.unique()\n",
    "            for data in tqdm(dates, desc = \"cleaning\"):\n",
    "                if len(df[df.data == data].codice_provincia.unique()) != n_nodes:\n",
    "                    df = df[-(df.data == data)]\n",
    "            \n",
    "            df.sort_values(by=\"data\")\n",
    "            df[[f\"variazione_{x}\" for x in config['dataset']['col_numerical']]]= df.groupby(by = 'codice_provincia').diff()[config['dataset']['col_numerical']]\n",
    "            df.dropna(inplace=True)\n",
    "            df.rename(columns={'variazione_totale_casi': 'nuovi_casi'}, inplace=True)\n",
    "            df = df.reset_index(drop = True)\n",
    "            df = df[list(df.drop(columns = config['dataset']['col_categorical']).columns)+ config['dataset']['col_categorical']]\n",
    "            ################# Date variables ########################\n",
    "             \n",
    "            df['year'] = df.data.dt.year-df.data.dt.year.min()\n",
    "            df['month'] = df.data.dt.month-df.data.dt.month.min()\n",
    "            df['day'] = df.data.dt.day-df.data.dt.day.min()\n",
    "            df['dayofweek'] = df.data.dt.dayofweek\n",
    "            df['weekend'] = [0 if x<6 else 1 for x in df.dayofweek]\n",
    "\n",
    "            ################# Saving the dataset #####################\n",
    "            #codice_reg_prov.to_csv(os.path.join(config['paths']['data'],\"codice_reg_prov.csv\"))\n",
    "            df.to_csv(os.path.join(config['paths']['data'],\"covid.csv\"))\n",
    "            \n",
    "    return df\n",
    "    \n",
    "data = get_dataset(config)\n",
    "data.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
