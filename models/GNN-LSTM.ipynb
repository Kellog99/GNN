{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880f767c-063e-41ab-b717-159c314557f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from data import covid_dataset\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89286644-478c-45ea-b4c4-51357958de33",
   "metadata": {},
   "source": [
    "Carico il configuratore che tiene traccia di tutte le informazioni generali "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70ea09f7-d49a-4aff-bcd2-e1bf7e5c97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./config.yaml\", 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf7d157b-cf41-4236-99c3-335cceca7d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10, 107, 10])\n",
      "torch.Size([64, 4, 107])\n"
     ]
    }
   ],
   "source": [
    "past_step = config['setting']['past_step']\n",
    "future_step = config['setting']['future_step']\n",
    "batch_size= 64#config['setting']['batch_size']\n",
    "\n",
    "if config['dataset']['aggregate']:\n",
    "    dataset = torch.load(os.path.join(config['paths']['data'],f\"aggregate/dataset{past_step}_{future_step}.pt\"))\n",
    "    len_train = int(len(dataset)*0.75)\n",
    "    len_val = len(dataset)-len_train\n",
    "    df_train, df_val = torch.utils.data.random_split(dataset=dataset, lengths = [len_train, len_val])\n",
    "    dl_train = DataLoader(dataset=df_train, batch_size=batch_size, shuffle=True)\n",
    "    dl_val = DataLoader(dataset=df_val, batch_size=batch_size, shuffle=True)\n",
    "    batch, y, adj = next(iter(dl_train))\n",
    "    print(batch.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "else:\n",
    "    dl_train = {}\n",
    "    dl_val = {}\n",
    "    for regione in df.codice_regione.unique():\n",
    "        dataset = torch.load(os.path.join(config['paths']['data'],f\"not_aggregate/dataset{regione}_{past_step}_{future_step}.pt\"))\n",
    "        len_train = int(len(dataset)*0.75)\n",
    "        len_val = len(dataset)-len_train\n",
    "        df_train, df_val = torch.utils.data.random_split(dataset=dataset, lengths = [len_train, len_val])\n",
    "        dl_train[regione] = DataLoader(dataset=df_train, batch_size=batch_size, shuffle=True)\n",
    "        dl_val[regione] = DataLoader(dataset=df_val, batch_size=batch_size, shuffle=True)\n",
    "    batch, y = next(iter(dl_train[regione]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23b5eaa1-a59d-41a7-8960-cab807a39903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 107])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class pre_processing(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_feat:int, \n",
    "                 out_feat:int, \n",
    "                 categorical:list,\n",
    "                 dim_categorical:int, \n",
    "                 concat:bool, \n",
    "                 dropout:float, \n",
    "                 embedding: bool):\n",
    "        \n",
    "        super(pre_processing, self).__init__()\n",
    "        self.in_feat = in_feat\n",
    "        self.concat = concat\n",
    "        self.embedding = embedding\n",
    "        self.embedding = nn.ModuleList([nn.Embedding(categorical[i], dim_categorical) for i in range(len(categorical))])\n",
    "        out = in_feat + (dim_categorical-1)*len(categorical) if concat else in_feat + dim_categorical - len(categorical)\n",
    "        self.linear = nn.Sequential(nn.Linear(in_features = out, out_features = 128),\n",
    "                                    nn.Sigmoid(), \n",
    "                                    nn.Linear(in_features = 128, out_features = out_feat))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.embedding:\n",
    "            out = []\n",
    "            # Con l'unsqueeze creo una nuova dimensione ed Ã¨ come se mi salvassi per ogni features di ogni nodo di ogni batch tutti gli embedding\n",
    "            # Questo solo se devo sommare tutti gli embedding\n",
    "            for i in range(len(self.embedding)):\n",
    "                if self.concat:\n",
    "                    cat_tmp = x[:, :, :, -len(self.embedding)+i].int()\n",
    "                else:\n",
    "                    cat_tmp = x[:, :,:, -len(self.embedding)+i].int().unsqueeze(-1)\n",
    "                out.append(self.embedding[i](cat_tmp))\n",
    "\n",
    "            out = torch.cat(out,-1 if self.concat else -2)\n",
    "            out = out if self.concat else torch.sum(out, -2)\n",
    "            out = torch.cat((x[:,:,:,:-len(self.embedding)], out), -1)\n",
    "  \n",
    "        out = self.linear(out.float())\n",
    "        \n",
    "        return out.float()\n",
    "\n",
    "    \n",
    "\n",
    "class my_gcnn(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 in_channels: int, \n",
    "                 out_channels: int,\n",
    "                 past:int, \n",
    "                 relu: bool = True):\n",
    "        super(my_gcnn, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.past = past \n",
    "        self.lin = nn.Linear(in_channels, \n",
    "                             out_channels, \n",
    "                             bias = False)\n",
    "        self.emb = nn.Linear(in_channels, \n",
    "                             256, \n",
    "                             bias = False)\n",
    "        self.relu = nn.ReLU()\n",
    "        if relu:\n",
    "            self.act = nn.ReLU()\n",
    "        else:\n",
    "            self.act = nn.Identity()\n",
    "        \n",
    "\n",
    "    def forward(self,\n",
    "                x0: tuple) -> torch.tensor:\n",
    "        \n",
    "        x, A = x0   \n",
    "        x_emb = self.emb(x)\n",
    "        pi = torch.einsum('bdjk,bdik->bdij', x_emb, x_emb)\n",
    "        # Define the value you want to fill in the masked positions\n",
    "        fill_value = -float('infinity')\n",
    "        # Apply the mask to fill values in the input tensor\n",
    "        pi = F.softmax(pi.masked_fill(A == 0., fill_value), -1)\n",
    "        x = torch.einsum('bpik,bpkj->bpij', pi, x)\n",
    "        x = self.lin(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        return (x, A)\n",
    "\n",
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTMCell, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # LSTM weights and biases\n",
    "        self.W_i = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.W_f = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.W_o = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.W_g = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        h_prev, c_prev = hidden\n",
    "        \n",
    "        # Concatenate input and previous hidden state\n",
    "        combined = torch.cat((x, h_prev), dim=-1)\n",
    "\n",
    "        # Compute the input, forget, output, and cell gates\n",
    "        i = torch.sigmoid(self.W_i(combined))\n",
    "        f = torch.sigmoid(self.W_f(combined))\n",
    "        o = torch.sigmoid(self.W_o(combined))\n",
    "        g = torch.tanh(self.W_g(combined))\n",
    "\n",
    "        # Update the cell state and hidden state\n",
    "        c = f * c_prev + i * g\n",
    "        h = o * torch.tanh(c)\n",
    "\n",
    "        return h, c\n",
    "        \n",
    "        \n",
    "class GLSTM(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_feat:int, \n",
    "                 past: int, \n",
    "                 future: int,\n",
    "                 categorical:list,\n",
    "                 device, \n",
    "                 out_preprocess:int = 32, \n",
    "                 dropout: float = 0.1, \n",
    "                 embedding:bool = True, \n",
    "                 dim_categorical:int = 16, \n",
    "                 concat:bool = True,\n",
    "                 num_layer_gnn:int = 1,\n",
    "                 hidden_gnn:int = 128,\n",
    "                 hidden_lstm: int = 256, \n",
    "                 hidden_propagation:int = 256):\n",
    "        \n",
    "        super(GLSTM, self).__init__()\n",
    "        \n",
    "        self.out_gnn = 1#nfeat_out_gnn        \n",
    "        self.in_feat = in_feat         # numero di features di ogni nodo prima del primo GAT        \n",
    "        self.past = past \n",
    "        self.future = future\n",
    "        self.embedding = embedding\n",
    "        self.hidden_gnn = hidden_gnn\n",
    "        self.hidden_lstm = hidden_lstm\n",
    "        self.device = device\n",
    "        ########## PREPROCESSING PART #############        \n",
    "        # preprossessing dell'input\n",
    "        self.out_preprocess = out_preprocess\n",
    "        self.pre_processing = pre_processing(in_feat = in_feat, \n",
    "                                             out_feat = out_preprocess, \n",
    "                                             categorical = categorical,\n",
    "                                             embedding = embedding, \n",
    "                                             dropout = dropout, \n",
    "                                             dim_categorical = dim_categorical, \n",
    "                                             concat = concat)\n",
    "        \n",
    "        ########## FIRST GNN PART #############\n",
    "        # LA CGNN mi permette di vedere spazialmente la situazione circostante\n",
    "        # piÃ¹ layer di CGNN piÃ¹ spazialmente distante arriva l'informazione\n",
    "        # B x P x N x F\n",
    "    \n",
    "        layers = []\n",
    "        \n",
    "        for i in range(num_layer_gnn):\n",
    "            in_channels = self.out_preprocess if i == 0 else hidden_gnn\n",
    "            #out_channels = self.out_gnn if i == (num_layer_gnn - 1) else hidden_gnn\n",
    "            #relu = True if i != (num_layer_gnn - 1) else False\n",
    "            layers.append(my_gcnn(in_channels = in_channels, \n",
    "                                  out_channels = hidden_gnn, \n",
    "                                  past = past,\n",
    "                                  relu = True))            \n",
    "        self.gnn = nn.Sequential(*layers)\n",
    "\n",
    "        self.lstm = LSTMCell(input_size = hidden_gnn, \n",
    "                             hidden_size = hidden_lstm)\n",
    "        self.lstm_future = LSTMCell(input_size = hidden_lstm, \n",
    "                                    hidden_size = hidden_lstm)\n",
    "        \n",
    "        self.decoding = nn.Sequential(nn.Linear(in_features = hidden_lstm, \n",
    "                                                out_features = hidden_propagation), \n",
    "                                      nn.Tanh(),\n",
    "                                      nn.Linear(in_features = hidden_propagation,\n",
    "                                                out_features = future_step))\n",
    "               \n",
    "    def forward(self, x, adj):\n",
    "        ########### pre-processing dei dati ##########\n",
    "        x = self.pre_processing(x)\n",
    "        nodes = x.shape[-2]\n",
    "        ########## GNN processing ######################\n",
    "        x, _ = self.gnn((x, adj))\n",
    "        \n",
    "        batch_size, seq_len, nodes, features = x.size()\n",
    "\n",
    "        # Initialize hidden and cell states\n",
    "        h, c = [torch.zeros(batch_size, nodes, self.hidden_lstm).to(x.device)] * 2\n",
    "        for t in range(seq_len):\n",
    "            h, c = self.lstm(x[:, t], (h, c))  \n",
    "        x = self.decoding(h)\n",
    "        return  x.transpose(-2,-1)\n",
    "model = GLSTM(in_feat = batch.shape[-1], \n",
    "              past = past_step,\n",
    "              future = future_step,\n",
    "              categorical = config['model']['categorical'],\n",
    "              embedding = config['model']['embedding'],\n",
    "              device = torch.device('cpu'))\n",
    "yh = model(batch.to(model.device), adj.to(model.device))\n",
    "yh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7af7b368-eb3d-4c38-8dc1-40e7caeba1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(model, \n",
    "         dataloader,\n",
    "         optimizer,\n",
    "         criterion,\n",
    "         training: bool = False):\n",
    "\n",
    "    if training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    desc = \"training\" if training else \"validation\"\n",
    "    is_train = True if training else False\n",
    "    loss_epoch = 0.0\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        for x, y, adj in iter(dataloader):\n",
    "            x = x.to(model.device).float()\n",
    "            y = y.to(model.device).float()\n",
    "            yh = model(x, adj.to(model.device))\n",
    "            overall = F.l1_loss(yh.sum(-1), y.sum(-1))\n",
    "            loss = criterion(yh, y) + overall\n",
    "    \n",
    "            # Backward and optimize\n",
    "            if training:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # blocking the gradient summation \n",
    "                optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "            loss_epoch += loss.item()/len(dataloader)\n",
    "\n",
    "    return loss_epoch\n",
    "\n",
    "\n",
    "def training(model, \n",
    "             train_loader, \n",
    "             val_loader, \n",
    "             num_epochs, \n",
    "             criterion,\n",
    "             optimizer):\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "    be = np.inf\n",
    "    bm = model\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "            \n",
    "        # Calculate average loss for the epoch\n",
    "        loss = step(model = model, \n",
    "                         dataloader = train_loader, \n",
    "                         optimizer = optimizer, \n",
    "                         criterion = criterion,\n",
    "                         training = True)\n",
    "        \n",
    "        loss_train.append(loss)\n",
    "        \n",
    "        loss = step(model = model, \n",
    "                         dataloader = val_loader, \n",
    "                         optimizer = optimizer, \n",
    "                         criterion = criterion,\n",
    "                         training = False)\n",
    "        \n",
    "        loss_val.append(loss)\n",
    "        \n",
    "        if (loss_val[-1]<be) & (epoch/num_epochs>0.15):\n",
    "            be = loss_val[-1]\n",
    "            bm = model\n",
    "        if (epoch+1)%10 == 0:\n",
    "            print(f\"loss train epoch {epoch+1} == {loss_train[-1]}\")\n",
    "            print(f\"loss val epoch {epoch+1} == {loss_val[-1]}\")\n",
    "    return bm, loss_train, loss_val\n",
    "\n",
    "def training_not_aggregate(model, \n",
    "                           dl_train:dict, \n",
    "                           dl_val:dict, \n",
    "                           num_epochs:int, \n",
    "                           criterion,\n",
    "                           device,\n",
    "                           optimizer):\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "    be = np.inf\n",
    "    bm = model\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        loss_train.append(0)\n",
    "        loss_val.append(0)\n",
    "        \n",
    "        for key in dl_val.keys():   \n",
    "            # Calculate average loss for the epoch\n",
    "            loss = step(model = model, \n",
    "                        dataloader = dl_train[key], \n",
    "                        optimizer = optimizer, \n",
    "                        device = device,\n",
    "                        criterion = criterion,\n",
    "                        training = True)\n",
    "            \n",
    "            loss_train[-1]+= loss\n",
    "            \n",
    "            loss = step(model = model, \n",
    "                             dataloader = dl_val[key], \n",
    "                             optimizer = optimizer, \n",
    "                             device = device,\n",
    "                             criterion = criterion,\n",
    "                             training = False)\n",
    "            \n",
    "            loss_val[-1]+= loss\n",
    "            \n",
    "        loss_train[-1] = loss_train[-1]/len(dl_val.keys())\n",
    "        loss_val[-1] = loss_val[-1]/len(dl_val.keys())\n",
    "        if (loss_val[-1]<be) & (epoch/num_epochs>0.15):\n",
    "            be = loss_val[-1]\n",
    "            bm = model\n",
    "        if (epoch+1)%10 == 0:\n",
    "            print(f\"loss train epoch {epoch+1} == {loss_train[-1]}\")\n",
    "            print(f\"loss val epoch {epoch+1} == {loss_val[-1]}\")\n",
    "    return bm, loss_train, loss_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8ebd3f-905f-4f17-8a1f-ca2e30fb1300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â                                    | 3/100 [00:59<32:12, 19.93s/it]"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "def linfty(y, yh, alpha = 0.01):\n",
    "    diff = torch.sum(torch.abs(y-yh).max(0)[0])\n",
    "    mse = F.l1_loss(y,yh)\n",
    "    return diff + alpha*mse\n",
    "    \n",
    "model = GLSTM(in_feat = batch.float().shape[-1], \n",
    "              past = past_step,\n",
    "              future = future_step,\n",
    "              categorical = config['model']['categorical'],\n",
    "              embedding = config['model']['embedding'],\n",
    "              device = device).to(device)\n",
    "        \n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr = 1e-4)\n",
    "if config['dataset']['aggregate']:\n",
    "    model, loss_training, loss_validation = training(model, \n",
    "                                                 train_loader = dl_train, \n",
    "                                                 val_loader = dl_val, \n",
    "                                                 num_epochs = 100, \n",
    "                                                 criterion = nn.L1Loss(reduction=\"mean\"),\n",
    "                                                 optimizer = optimizer)\n",
    "else:\n",
    "    model, loss_training, loss_validation = training_not_aggregate(model, \n",
    "                                                                   dl_train = dl_train, \n",
    "                                                                   dl_val = dl_val, \n",
    "                                                                   num_epochs = 100, \n",
    "                                                                   criterion = linfty,\n",
    "                                                                   optimizer = optimizer, \n",
    "                                                                   device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42db3198-91b0-4565-8454-130e4914a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(model, \n",
    "         config,\n",
    "         loss_training, \n",
    "         loss_validation, \n",
    "         name,\n",
    "         dl_train = dl_train,\n",
    "         dl_val = dl_val, \n",
    "         show = False):\n",
    "    fig = px.line({\"epochs\": range(1,len(loss_training)+1), \n",
    "                                   \"train\": loss_training, \n",
    "                                   \"validation\": loss_validation}, \n",
    "                                  x = \"epochs\", \n",
    "                                  y = [\"train\", \"validation\"], \n",
    "                                  title= f\"training loss for {name}\")\n",
    "    fig.add_vline(x = np.argsort(loss_validation)[0]+1)\n",
    "    fig.add_hline(y = np.min(loss_validation))\n",
    "    fig.write_html(os.path.join(config['paths']['fig'],'covid', f\"loss_gnn_{name}.html\"))\n",
    "    if show:\n",
    "        fig.show()\n",
    "    if config['dataset']['aggregate']:\n",
    "        batch_train, y_train = next(iter(dl_train))\n",
    "        batch_val, y_val = next(iter(dl_val))\n",
    "        yh_train = model(batch_train.float().to(device))\n",
    "        yh_val = model(batch_val.float().to(device))\n",
    "    else:\n",
    "        yh_train = []\n",
    "        yh_val = []\n",
    "        y_train = []\n",
    "        y_val = []\n",
    "        for key in dl_train.keys():\n",
    "            batch_train, yt = next(iter(dl_train[key]))\n",
    "            batch_val, yv = next(iter(dl_val[key]))\n",
    "            yh_train.append(model(batch_train.float().to(model.device)).detach().cpu())\n",
    "            yh_val.append(model(batch_val.float().to(model.device)).detach().cpu())\n",
    "            y_train.append(yt)\n",
    "            y_val.append(yv)\n",
    "        \n",
    "        yh_train = torch.cat(yh_train, -2).transpose(-1,-2)\n",
    "        yh_val = torch.cat(yh_val, -2).transpose(-1,-2)\n",
    "        y_train = torch.cat(y_train, -1)\n",
    "        y_val = torch.cat(y_val, -1)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows = y.shape[1], \n",
    "                           ncols = 2, \n",
    "                           constrained_layout = True,\n",
    "                           figsize = (20,10))\n",
    "    \n",
    "    for day in range(y.shape[1]):\n",
    "        ax[day, 0].plot(yh_train[0,day].detach().cpu().numpy(), label = \"estimate\")\n",
    "        ax[day, 0].plot(y_train[0,day].numpy(), label =\"real\")\n",
    "    \n",
    "        ax[day, 1].plot(yh_val[0,day].detach().cpu().numpy(), label = \"estimate\")\n",
    "        ax[day, 1].plot(y_val[0,day].numpy(), label =\"real\")\n",
    "        ax[day, 0].legend()\n",
    "        ax[day, 1].legend()\n",
    "    \n",
    "        ax[day, 0].title.set_text(f\"day {day +1} train\")\n",
    "        ax[day, 1].title.set_text(f\"day {day +1} validation\")\n",
    "    fig.suptitle(' Comparison between estimation and reality ', fontsize=20) \n",
    "    \n",
    "    path = os.path.join(config['paths']['fig'],'covid', f\"{name}.png\")\n",
    "    plt.savefig(path)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c4f5d1-6c33-4266-9905-7587bccadfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model,\n",
    "     config,\n",
    "     loss_training, \n",
    "     loss_validation, \n",
    "     \"GLSTM\", \n",
    "     show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a28b25a-6f13-49f3-a078-a13a1ba194ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = False\n",
    "if grid_search:\n",
    "    path = os.path.join(config['paths']['models'], \"score.csv\")\n",
    "    if os.path.exists(path):\n",
    "        ord = pd.read_csv(path, index_col=0)\n",
    "        tmp = ord.to_dict('index')\n",
    "        score = {}\n",
    "        for k in tmp.keys():\n",
    "            score[tmp[k]['name']] = tmp[k]['score']\n",
    "    else:\n",
    "        score = {}\n",
    "    keys = config['grid_search'].keys()\n",
    "    def dfs(i:int, t:tuple, keys:list, config, comb:list):\n",
    "        if i == len(keys):\n",
    "            comb.append(t)\n",
    "        if i < len(keys):\n",
    "            if keys[i] == 'embedding':\n",
    "                comb.append(t+(False, ))\n",
    "                dfs(i+1, t+(True, ), keys, config, comb)\n",
    "            else:\n",
    "                for element in config['model'][keys[i]]:\n",
    "                    dfs(i+1, t+(element, ), keys, config, comb)\n",
    "    combs = []\n",
    "    dfs(0,(), keys, config, combs) \n",
    "    print(device)\n",
    "    for comb in combs:\n",
    "        name = f\"model_{config['setting']['past_step']}_{config['setting']['future_step']}_\"\n",
    "        for f in comb[:-1]:\n",
    "            name += f\"{f}_\"\n",
    "        name += f\"{comb[-1]}\"\n",
    "        if name not in list(score.keys()):\n",
    "            model = GNN(in_feat = batch.float().shape[-1], \n",
    "                        past = past_step,\n",
    "                        future = future_step,\n",
    "                        categorical = categorical,\n",
    "                        dropout = comb[0],\n",
    "                        out_preprocess = comb[1],\n",
    "                        num_layer_gnn = comb[2],\n",
    "                        hidden_propagation = comb[3],\n",
    "                        embedding = comb[4], \n",
    "                        concat = comb[5] if comb[4] else True,\n",
    "                        dim_categorical = comb[6] if comb[4] else 128,\n",
    "                        nodes = len(codice_reg_prov),\n",
    "                        adj = L).to(device)\n",
    "                    \n",
    "            optimizer = optim.Adam(model.parameters(), lr = 3e-4)\n",
    "            print(name)\n",
    "            model, loss_training, loss_validation = training(model, \n",
    "                                                             train_loader = dl_train, \n",
    "                                                             val_loader = dl_val, \n",
    "                                                             num_epochs = 100, \n",
    "                                                             criterion = nn.L1Loss(reduction=\"mean\"),\n",
    "                                                             optimizer = optimizer, \n",
    "                                                             device = device)\n",
    "            score[name] = np.min(loss_validation)\n",
    "            plot(model, \n",
    "                 config,\n",
    "                 loss_training, \n",
    "                 loss_validation, \n",
    "                 name)\n",
    "    ord = pd.DataFrame(score.items(), columns = [\"name\", \"score\"])\n",
    "    ord.sort_values(by = \"score\").reset_index(drop= True)\n",
    "    ord.to_csv(os.path.join(config['paths']['models'], \"score.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f018570-8b5a-486a-a505-a12b6a137667",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
